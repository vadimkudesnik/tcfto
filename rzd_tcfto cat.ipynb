{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install setuptools\n",
    "%pip install ydata_profiling\n",
    "%pip install scikit-learn\n",
    "%pip install xlrd\n",
    "%pip install openpyxl\n",
    "%pip install ipywidgets\n",
    "%pip install statsmodels\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from ydata_profiling import ProfileReport\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost\n",
    "from catboost import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes=pd.read_excel(\"././dataset/Объёмы перевозок.xls\", skiprows=[0], header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.sort_index(axis=1, inplace=True)\n",
    "num_col=len(excel_data_volumes.columns)\n",
    "left = excel_data_volumes.iloc[:, [num_col-5, num_col-4, num_col-3, num_col-2,num_col-1]]\n",
    "left.columns = left.columns.get_level_values(1)\n",
    "left = left.set_axis([\"id\", \"subj_from\", \"subj_to\", \"cargo_code\", \"cargo_type\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencodder = LabelEncoder()\n",
    "subj = pd.concat([left.loc[:, [\"subj_from\"]].rename(columns = {\"subj_from\": \"subj\"}), left.loc[:, [\"subj_to\"]].rename(columns = {\"subj_to\": \"subj\"})]).drop_duplicates(ignore_index=True)\n",
    "cargo_type = left.loc[:, [\"cargo_type\"]].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left.loc[:, [\"subj_from\"]] = left.loc[:, [\"subj_from\"]].apply(lambda x: subj[subj[\"subj\"] == x[\"subj_from\"]].index[0], axis=1)\n",
    "left.loc[:, [\"subj_to\"]] = left.loc[:, [\"subj_to\"]].apply(lambda x: subj[subj[\"subj\"] == x[\"subj_to\"]].index[0], axis=1)\n",
    "left.loc[:, [\"cargo_type\"]] = left.loc[:, [\"cargo_type\"]].apply(lambda x: cargo_type[cargo_type[\"cargo_type\"] == x[\"cargo_type\"]].index[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left[\"subj_from\"] = left[\"subj_from\"].astype(\"int64\")\n",
    "left[\"subj_to\"] = left[\"subj_to\"].astype(\"int64\")\n",
    "left[\"cargo_type\"] = left[\"cargo_type\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int((num_col-5)/2)):\n",
    "    right = excel_data_volumes.iloc[:, [i*2,i*2+1]]\n",
    "    date = pd.to_datetime(excel_data_volumes.iloc[:, [i*2]].columns.get_level_values(0).to_list()[0], format=\"%Y/%m\")\n",
    "    right.insert(2, (\"\", \"date\"), date)\n",
    "    right.insert(3, (\"\", \"month\"), date.month)\n",
    "    right.insert(4, (\"\", \"quarter\"), date.quarter)\n",
    "    right.insert(5, (\"\", \"year\"), date.year)\n",
    "    right.columns = right.columns.get_level_values(1)\n",
    "    right = right.set_axis([\"cargo_volume\", \"cargo_sales\", \"date\", \"month\", \"quarter\", \"year\"], axis=1)\n",
    "    if i == 0:\n",
    "        result = pd.concat([left, right], axis = 1, sort = False)\n",
    "    else:\n",
    "        result = pd.concat([result, pd.concat([left, right], axis = 1, sort = False)], axis = 0, ignore_index=True, sort=False)\n",
    "excel_data_volumes = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.insert(11, (\"month_of_period\"), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = excel_data_volumes[\"year\"].min()\n",
    "excel_data_volumes[\"month_of_period\"] = excel_data_volumes[\"year\"].apply(lambda x: x - min) + excel_data_volumes[\"month\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.insert(12, (\"innactive\"), 0)\n",
    "excel_data_volumes.insert(13, (\"active\"), 0)\n",
    "excel_data_volumes[\"innactive\"] = excel_data_volumes.apply(lambda x: 1 if ((x[\"cargo_volume\"] == 0) & (x[\"cargo_sales\"] == 0)) else 0, axis=1)\n",
    "excel_data_volumes[\"active\"] = excel_data_volumes.apply(lambda x: 1 if ((x[\"cargo_volume\"] > 0) & (x[\"cargo_sales\"] > 0)) else 0, axis=1)\n",
    "excel_data_volumes.drop(\"date\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_volumes.groupby([\"id\"]).count().iloc[:round(len(excel_data_volumes.groupby([\"id\"]).count())*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = excel_data_volumes\n",
    "\n",
    "data_pd[\"outflow\"] = 0\n",
    "\n",
    "def calc_innactive(row):\n",
    "    row_month_of_period = data_pd.iloc[row.name][\"month_of_period\"]\n",
    "    if row_month_of_period > 1:\n",
    "        subj_from = data_pd.iloc[row.name][\"subj_from\"]\n",
    "        subj_to = data_pd.iloc[row.name][\"subj_to\"]\n",
    "        cargo_code = data_pd.iloc[row.name][\"cargo_code\"]\n",
    "        # cargo_type = data_pd.iloc[row.name][\"cargo_type\"]\n",
    "        row_id = data_pd.iloc[row.name][\"id\"]\n",
    "        row_value = data_pd.iloc[row.name][\"innactive\"]\n",
    "        prev_row_value = data_pd.loc[(data_pd[\"subj_from\"] == subj_from) & (data_pd[\"subj_to\"] == subj_to) & (data_pd[\"cargo_code\"] == cargo_code) & (data_pd[\"month_of_period\"] == row_month_of_period -1) & (data_pd[\"id\"] == row_id)][\"innactive\"].values[0]\n",
    "        data_pd.iloc[row.name, data_pd.columns.get_loc(\"innactive\")] = prev_row_value + 1\n",
    "        row_value = data_pd.iloc[row.name][\"innactive\"]\n",
    "        if row_value > 11:\n",
    "            return 1\n",
    "        else:\n",
    "            return row_value/12\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd[\"outflow\"] = data_pd.apply(lambda x: calc_innactive(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd[data_pd[\"id\"] == 912]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_pd = excel_data_volumes.groupby([\"id\", \"date\"], as_index=False).sum()\n",
    "data_pd = data_pd.drop(data_pd.iloc[:, [2, 3, 4, 5]], axis=1)\n",
    "data_pd[\"innactive\"] = data_pd.apply(lambda x: 1 if ((x[\"cargo_volume\"] == 0) & (x[\"cargo_price\"] == 0)) else 0, axis=1)\n",
    "data_pd[\"active\"] = data_pd.apply(lambda x: 1 if ((x[\"cargo_volume\"] > 0) & (x[\"cargo_price\"] > 0)) else 0, axis=1)\n",
    "\n",
    "data_pd[\"outflow\"] = 0\n",
    "\n",
    "def calc_innactive(row):\n",
    "    prev_row_value = 0\n",
    "    row_value = data_pd.iloc[row.name][\"innactive\"]\n",
    "    row_id = data_pd.iloc[row.name][\"id\"]\n",
    "    if row.name > 0:\n",
    "        prev_row_id = data_pd.iloc[row.name - 1][\"id\"]\n",
    "        if row_id == prev_row_id:\n",
    "            if  row_value > 0:\n",
    "                prev_row_value = data_pd.iloc[row.name - 1][\"innactive\"]\n",
    "                data_pd.iloc[row.name, data_pd.columns.get_loc(\"innactive\")] = prev_row_value + 1\n",
    "                row_value = data_pd.iloc[row.name][\"innactive\"]\n",
    "                if row_value > 11:\n",
    "                    prev_row_value = 1\n",
    "                else:\n",
    "                    prev_row_value = row_value/12\n",
    "            else: \n",
    "                prev_row_value = 0\n",
    "    return prev_row_value\n",
    "\n",
    "def calc_active(row):\n",
    "    row_value = data_pd.iloc[row.name][\"active\"]\n",
    "    row_id = data_pd.iloc[row.name][\"id\"]\n",
    "    if row.name > 0:\n",
    "        prev_row_id = data_pd.iloc[row.name - 1][\"id\"]\n",
    "        if row_id == prev_row_id:\n",
    "            if  row_value > 0:\n",
    "                prev_row_value = data_pd.iloc[row.name - 1][\"active\"]\n",
    "                data_pd.iloc[row.name, data_pd.columns.get_loc(\"active\")] = prev_row_value + 1\n",
    "    return 0\n",
    "\n",
    "data_pd[\"outflow\"] = data_pd.apply(calc_innactive, axis=1)\n",
    "data_pd[\"innactive\"] = data_pd.apply(lambda x: 1 if ((x[\"cargo_volume\"] == 0) & (x[\"cargo_price\"] == 0)) else 0, axis=1)\n",
    "# data_pd.apply(calc_active, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fit = data_pd[data_pd[\"id\"] == 9]\n",
    "dataset_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим график продаж\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(dataset_fit['date'], dataset_fit['cargo_volume'], color=\"red\", marker='o', linestyle='-')\n",
    "plt.title('Объемы перевозок')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Объемы')\n",
    "plt.subplot(212)\n",
    "plt.plot(dataset_fit['date'], dataset_fit['cargo_price'], color=\"blue\", marker='o', linestyle='-')\n",
    "plt.title('Объемы продаж')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Продажи')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = data_pd\n",
    "# fit.to_excel(\"output.xlsx\")\n",
    "l = fit.drop(labels=\"date\", axis=1).groupby([\"id\"]).sum().apply(lambda x: x)\n",
    "r = fit.drop(labels=\"date\", axis=1).groupby([\"id\"]).outflow.last().apply(lambda x: x).rename(\"out\")\n",
    "\n",
    "fit_pd = pd.concat([l, r], axis=1).drop(\"outflow\", axis=1)\n",
    "fit_pd[\"out\"] = fit_pd.apply(lambda x: 1 if (x[\"out\"] == 1) else 0, axis=1).astype(\"int64\")\n",
    "fit_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(fit_pd, minimal = True) # Формирование отчета для исследования данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pd.mean() # расчет средних значений признаков для тех кто ушел и остался"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pd.groupby(by = \"out\").mean() # расчет средних значений признаков для тех кто ушел и остался"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = fit_pd.corr() # матрица корреляций\n",
    "fig, ax = plt.subplots(figsize=(15,5)) \n",
    "sns.heatmap(cor, annot = True, fmt = \".2f\") # тепловая карта на основе матрицы корреляций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_pd[[\"cargo_volume\", \"cargo_price\"]] = scaler.fit_transform(data_pd[[\"cargo_volume\", \"cargo_price\"]])\n",
    "\n",
    "cor = data_pd.corr() # матрица корреляций\n",
    "fig, ax = plt.subplots(figsize=(15,5)) \n",
    "sns.heatmap(cor, annot = True, fmt = \".2f\") # тепловая карта на основе матрицы корреляций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "fit_pd[[\"cargo_volume\", \"cargo_price\"]] = scaler.fit_transform(fit_pd[[\"cargo_volume\", \"cargo_price\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fit_pd.drop(\"out\", axis = 1)\n",
    "y=fit_pd[\"out\"] # разделение данных на признаки (матрица X) и целевую переменную (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0) # разделение модели на обучающую и валидационную выборку\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)  \n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)[:,1]\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "precision = precision_score (y_test, predictions)\n",
    "recall = recall_score (y_test, predictions)\n",
    "print(acc, precision, recall) # вывод на экран метрик, характеризующих качество модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test) \n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "precision_rf = precision_score (y_test, y_pred)\n",
    "recall_rf = recall_score (y_test, y_pred)\n",
    "print(acc_rf, precision_rf, recall_rf)# вывод на экран метрик, характеризующих качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_sc = sc.fit_transform(X)\n",
    "linked = linkage(X_sc, method = \"ward\")\n",
    "plt.figure(figsize=(15, 10))  \n",
    "dendrogram(linked, orientation=\"top\")\n",
    "plt.show() # вывод на экран дендрограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 2 # количество кластеров выбранов соответствии с дендрограммой, а также на основе анализа нескольких вариантов\n",
    "km = KMeans(n_clusters = cl)\n",
    "labels = km.fit_predict(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pd[\"claster\"]= labels # добавление колонки с категориями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.pivot_table(data = fit_pd, index = \"claster\", columns = \"out\", values = \"cargo_volume\", aggfunc = \"count\" ).reset_index() # формирование сводной таблицы для анализа оттока по категориям\n",
    "piv.columns = [\"claster\",\"out_0\",\"out_1\"]\n",
    "piv[\"perc\"] = piv[\"out_1\"]/(piv[\"out_0\"]+piv[\"out_1\"])\n",
    "piv[\"number\"]=piv[\"out_1\"]+piv[\"out_0\"]\n",
    "print(piv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = fit_pd.corr()\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.heatmap(cor, annot = True, fmt = \".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pd.groupby(by = 'claster').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
